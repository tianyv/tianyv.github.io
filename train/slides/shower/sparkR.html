<!DOCTYPE HTML>
<html lang="en-US">
<head>
	<title>Running Spark on R</title>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=1274, user-scalable=no">
	<meta name="description" content="Running Spark on R">
	<meta name="author" content="赖韬">
	<meta name="generator" content="slidify" />
	<!-- LOAD STYLE SHEETS -->
	<link rel="stylesheet" href="libraries/frameworks/shower/themes/w3c/styles/screen.css">
	<link rel="stylesheet" media="print"
	  href="libraries/frameworks/shower/themes/ribbon/styles/print.css">
	<link rel="stylesheet" href="libraries/highlighters/prettify/css/tomorrow.css">  
<link rel="stylesheet" href = "assets/css/ribbons.css">
<link rel="stylesheet" href="libraries/highlighters/prettify/css/prettify.css">

	<!--
		To apply styles to the certain slides
		use slide ID to get needed elements
		-->
	<style>
		#Cover h2 {
      margin:65px 0 0;
			color:#FFF;
			text-align:center;
			font-size:70px;
			}
		#FitToWidth h2,
		#FitToHeight h2 {
			color:#FFF;
			text-align:center;
			}
	.slide{font-size:20px;}
 td{font-size:20px;}
   pre{
      white-space: pre-wrap!important;
      word-wrap: break-word!important;
      *white-space:normal!important;
      }  
  </style>
</head>
<body class="list">
  <header class="caption">
  	<h1>Running Spark on R</h1>
	</header>
  <section class="slide shout shrink">
  <div>
    <h2><p>SparkR</p>
</h2>
  </div>
</section>
<section class="slide " id="slide-2">
  <div>
    <h2>一、Spark 简介</h2>
    <h5>1.1核心组件</h5>

<div style='float:left;width:48%;white-space:nowrap;font-size:18px;'>
  <ul>
<li>RDD 弹性分布式数据集

<ul>
<li>SparkContext.textFile()</li>
<li>rdd-&gt;transformation-&gt;action-&gt;rdd</li>
<li>DAG（有向无环图）作业调度系统  <strong>宽窄依赖</strong></li>
</ul></li>
<li>Spark Streaming 实时流处理 

<ul>
<li>StreamingContext</li>
<li>核心 <strong>DStream</strong> {KDY=&gt;time,VALUE=&gt;rdd}</li>
<li>DStreamDAG</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:48%;white-space:nowrap;font-size:18px;'>
  <ul>
<li>Graphx 图计算</li>
<li>Spark SQL 交互式大数据SQL技术

<ul>
<li>将sql语句<strong>翻译</strong>成Spark上的RDD操作</li>
</ul></li>
<li>SparkR

<ul>
<li>允许用户使用R交互式方式在<strong>集群</strong>中运行任务</li>
<li>集成MLlib机器学习库</li>
</ul></li>
</ul>

<p><img src="img/00spark.png" width = "400"></p>

</div>
  </div>
</section>
<section class="slide " id="slide-3">
  <div>
    <h2>一、Spark 简介</h2>
    <h5>1.2Transformations（转换）</h5>

<div style='float:left;width:48%;white-space:nowrap;font-size:17px;'>
  <ul>
<li>Map

<ul>
<li>类似<strong>遍历转换</strong>，结果为MappedRDD</li>
</ul></li>
<li>flatMap

<ul>
<li>将RDD每个集合中的元素<strong>合并</strong>成一<br>
个集合</li>
</ul></li>
<li>Union

<ul>
<li>将2个RDD合并成1个，前题必须保证两<br>
RDD元素的数据类型相同</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:48%;white-space:nowrap;font-size:17px;'>
  <ul>
<li>Filter

<ul>
<li>对元素进行过滤，返回元素值为<strong>TRUE</strong>的RDD</li>
<li>类似的有<strong>去重</strong>：Distinct、<strong>交集</strong>：Subtract、<strong>抽样</strong>：Sample</li>
</ul></li>
<li>Key=&gt;Value操作

<ul>
<li>groupByKey、<strong>reduceByKey</strong></li>
<li>sortByKey、aggregateByKey</li>
<li>join 建议用小RDD去join大RDD</li>
</ul></li>
</ul>

</div>
  </div>
</section>
<section class="slide " id="slide-4">
  <div>
    <h2>一、Spark 简介</h2>
    <h5>1.3Actions（动作）</h5>

<div style='float:left;width:48%;white-space:nowrap;font-size:18px;'>
  <ul>
<li>reduce

<ul>
<li>通过fun接受<strong>2个</strong>参数返回<strong>一个</strong>值</li>
<li>rdd.map(s =&gt; s.length).reduce((a, b)=&gt; a + b)</li>
</ul></li>
<li>collect

<ul>
<li>以<strong>数组</strong>形式返回RDD的所有元素</li>
</ul></li>
<li>count

<ul>
<li>返回RDD元素的个数<strong>n</strong></li>
</ul></li>
<li>first

<ul>
<li>返回RDD<strong>第一</strong>个元素</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:48%;white-space:nowrap;font-size:18px;'>
  <ul>
<li>saveAsTextFile</li>
<li>foreach

<ul>
<li>在RDD的<strong>每个</strong>元素上运行fun</li>
</ul></li>
<li>Cache 

<ul>
<li>将RDD缓存到<strong>内存</strong>中</li>
</ul></li>
<li>Persist 

<ul>
<li>将RDD存<strong>磁盘</strong>或<strong>内存</strong>，3种组合方式</li>
</ul></li>
</ul>

</div>
  </div>
</section>
<section class="slide " id="slide-5">
  <div>
    <h2>一、Spark 简介</h2>
    <h5>1.4Shuffle 洗牌</h5>

<pre>Spark需要执行一个all-to-all操作。它必须读取所有分区，找到所有key的值，并跨分区把这些值放到一起来计算每个key的最终结果  
                                                                      ——这就叫做洗牌
</pre>

<pre>sc.textFile(&quot;hdfs://...&quot;)
  .flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_).saveAsTextFile(hdfs://...)
</pre>

  </div>
</section>
<section class="slide " id="slide-6">
  <div>
    <h2>二、Why SparkR</h2>
    
<div style='float:left;width:15%;white-space:nowrap;font-size:20px;'>
  <p><img src="img/01sparkR.png" width = "200"></p>

<ul>
<li>Big Data</li>
<li>Small Learning</li>
<li>SparkRSQL</li>
<li>Machine Learning</li>
<li>Partition</li>
<li>Aggregate</li>
</ul>

</div>
<div style='float:right;width:70%;white-space:nowrap;font-size:14px;'>
  <p><img src="img/02sparkR.png" width = "550"></p>

</div>
  </div>
</section>
<section class="slide " id="slide-7">
  <div>
    <h2>三、Spark 单机环境搭建</h2>
    
<div style='float:left;width:85%;white-space:nowrap;font-size:13px;'>
  <ul>
<li><strong>安装 JDK1.7</strong>

<ul>
<li>双击运行jdk-7u79-windows-i586.exe</li>
<li>添加环境变量 </li>
<li>新建 JAVA_HOME  值：\Java\jdk1.7.0_79 </li>
<li>新建 CLASSPATH  值：.;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar</li>
<li>修改 PATH       值：%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin </li>
<li>$cmd java -version</li>
<li>$cmd JAVAC</li>
</ul></li>
<li><strong>安装 Scala 2.10.4</strong>

<ul>
<li>新建 SCALA_HOME  值：\scala </li>
<li>修改 PATH        值：%SCALA_HOME%\bin</li>
<li>$cmd scala -version</li>
</ul></li>
<li><strong>安装 Spark</strong>

<ul>
<li>解压 spark-1.4.0-bin-hadoop2.3.tgz到c:\spark</li>
<li>新建 SPARK_HOME  值：c:\spark</li>
<li>修改 PATH        值：%SPARK_HOME%\bin</li>
<li>$cmd start-master.sh 或 spark-shell 或 sparkR</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:10%;white-space:nowrap;font-size:16px;'>
  
</div>
  </div>
</section>
<section class="slide " id="slide-8">
  <div>
    <h2>四、WordCount</h2>
    
<div style='float:left;width:48%;white-space:nowrap;font-size:13px;'>
  <pre>#4.1RDD api
.libPaths(c(file.path(Sys.getenv(&quot;SPARK_HOME&quot;),&quot;R&quot;,&quot;lib&quot;), .libPaths()))
library(SparkR)
sc &lt;- sparkR.init(master=&quot;local[2]&quot;,appName=&quot;WordCount&quot;)
lines &lt;- SparkR:::textFile(sc, &#39;README.md&#39;)
words &lt;- SparkR:::flatMap(lines,
                 function(line) {
                   strsplit(line, &quot; &quot;)[[1]]
                 })
wordCount &lt;- SparkR:::lapply(words, function(word) { list(word, 1L) })
counts &lt;- SparkR:::reduceByKey(wordCount, &quot;+&quot;, 2L)
output &lt;- SparkR:::collect(counts)
for (wordcount in output) {
  cat(wordcount[[1]], &quot;: &quot;, wordcount[[2]], &quot;\n&quot;)
}
</pre>

</div>
<div style='float:right;width:48%;white-space:nowrap;font-size:14px;'>
  <pre>#4.2DataFrame api
.libPaths(c(file.path(Sys.getenv(&quot;SPARK_HOME&quot;),&quot;R&quot;,&quot;lib&quot;), .libPaths()))
library(SparkR)
library(magrittr)
sc &lt;- sparkR.init(master=&quot;local[2]&quot;,appName=&quot;WordCount&quot;)
sqlCtx &lt;- sparkRSQL.init(sc)
localDF &lt;- data.frame(w=c(&quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;))
df&lt;-createDataFrame(sqlCtx, localDF)
wordcount&lt;- df %&gt;% group_by(df$w) %&gt;% summarize(count = n(df$w)) %&gt;% collect()
print(wordcount)
</pre>

</div>
  </div>
</section>
<section class="slide " id="slide-9">
  <div>
    <h2>五、sparkR 弹性分布式数据集</h2>
    
<div style='float:left;width:48%;white-space:nowrap;font-size:17px;'>
  <h4><strong>类型1：DataFrame</strong></h4>

<ul>
<li><strong>创建</strong>

<ul>
<li>createDataFrame 从R data frame转换</li>
<li>read.df或loadDF 读取<strong>Parquet</strong>、JSON、CSV文件</li>
<li>hiveCtx.sql()   hiveCtx &lt;- sparkRHive.init(sc)

<ul>
<li>从<strong>HiveContext</strong>开始</li>
</ul></li>
</ul></li>
<li>从<strong>SparkContext</strong>和<strong>SQLContext</strong>开始

<ul>
<li>sc &lt;- sparkR.init</li>
<li>sqlCtx &lt;- sparkRSQL.init(sc)</li>
</ul></li>
<li>转换集合类型

<ul>
<li>toRDD toJSON</li>
</ul></li>
<li><strong>注册临时表使用sql查询</strong>

<ul>
<li>registerTempTable(df, &quot;dfName&quot;)</li>
</ul></li>
</ul>

</div>
<div style='float:right;width:48%;white-space:nowrap;font-size:17px;'>
  <h4><strong>类型2：RDD</strong></h4>

<ul>
<li><strong>创建</strong>

<ul>
<li>paralleliae 从list或vector创建</li>
<li>textFile    从文本文件创建</li>
<li>objectFile  从object文件载入</li>
</ul></li>
<li><strong>转换方法</strong>

<ul>
<li>map=                     df-&gt;lapply</li>
<li>flatMap</li>
<li>mapPartitions=           df-&gt;lapplyPartition</li>
<li>mapPartitionsWithIndex=  df-&gt;lapplyPartitionsWithIndex</li>
</ul></li>
</ul>

</div>
  </div>
</section>

<section class="slide " id="slide-10">
  <div>
    <h2>未完，课件正在编写中...</h2>
    <p>返回Blog: <a href="http://tianyv.github.io/train">http://tianyv.github.io/train</a></p>
  </div>  
 </section>   
  <div class="progress">
    <div></div>
  </div>
	<script src="libraries/frameworks/shower/shower.js"></script>
	<!-- Google Prettify -->
	<script src="libraries/highlighters/prettify/js/prettify.js"></script>
	<script src=''></script>
	<script>
	  var pres = document.getElementsByTagName("pre");
	  for (var i=0; i < pres.length; ++i) {
	    pres[i].className = "prettyprint";
	  }
	  prettyPrint();
	</script>
	<!-- End Google Prettify --> 
		<!-- Copyright © 2010–2012 Vadim Makeev — pepelsbey.net -->
	<!-- Photos by John Carey — fiftyfootshadows.net -->
</body>
</html>
